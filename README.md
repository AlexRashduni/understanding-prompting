# Understanding the prompting capabilities of pretrained language models

Pretrained language models have been shown to be highly effective at a variety of natural language processing tasks, but there is still much to learn about how to best prompt these models to achieve optimal performance. This thesis examines the prompting capabilities of pretrained language models, specifically focusing on the T0 model and ChatGPT. Through a comprehensive literature review, we explore the current state of research on prompting and its potential applications in natural language processing. We then benchmark the T0 model's performance in various datasets including BIG-Bench Lite, demonstrating its strengths and limitations. Following our evaluation of T0, we investigate ChatGPT's potential in few-shot semantic parsing, finding that it performs well in predicting structured representations of natural language queries with minimal training data. Finally, we evaluate ChatGPT's zero-shot software engineering and development capabilities, showing that it can generate syntactically correct and semantically relevant code snippets given natural language prompts. This thesis highlights the significance of prompting as a powerful technique for natural language processing, and the potential of pretrained language models in various domains.
